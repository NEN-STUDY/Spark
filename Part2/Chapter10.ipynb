{"cells":[{"cell_type":"markdown","source":["# 스파크 SQL\n- 스파크 SQL을 사용해서 다음과 같은 작업을 수행할 수 있음\n  - 데이터베이스에 생성된 <strong>뷰나 테이블에 SQL쿼리 실행</strong>\n  - <strong>시스템 함수</strong>를 사용\n  - <strong>사용자 정의 함수</strong> 정의\n  - <strong>워크로드를 최적화</strong> 하기 위해 <strong>쿼리 실행 계획 분석</strong>\n\n- 스파크 SQL은 <strong>DataFrame과 Dataset API에 통합</strong>되어 있음"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"84f6b8a8-f9d0-4266-8da1-92741e01300f"}}},{"cell_type":"markdown","source":["## SQL이란\n- <strong>SQL(Structured Query Language)</strong>은 <strong>데이터에 대한 관계형 연산</strong>을 표현하기 위한 도메인 특화 언어\n- 모든 관계형 DB에 사용되며 많은 NoSQL DB에서도 쉽게 사용할 수 있는 변형된 자체 SQL제공\n- 스파크는 <strong>ANSI SQL:2003</strong>의 일부를 구현했음\n  - 이는 대부분의 SQL DB에서 채택하고 있는 표준임"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4a1f9554-3703-43ea-a4cd-7e624b94981e"}}},{"cell_type":"markdown","source":["## 빅데이터와 SQL: 아파치 하이브\n- [하이브 참고](https://ko.wikipedia.org/wiki/%EC%95%84%ED%8C%8C%EC%B9%98_%ED%95%98%EC%9D%B4%EB%B8%8C)\n  - 하둡에서 동작하는 데이터 웨어하우스(Data Warehouse) 인프라 구조로서 데이터 요약, 질의 및 분석 기능 제공\n- <strong>스파크가 등장하기 전에는 Hive</strong>가 빅데이터 SQL 접근 계층에서 사실상 표준이었음\n  - 하이브는 페북에서 개발\n  - SQL처리가 필요한 빅데이터 업계에서 믿을 수 없을 정도로 인기 있는 도구였음\n  - <strong>하둡을 다양한 산업군으로 진출</strong>시키는 데 다방면으로 도움을 주었음"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8fb97f13-3880-4965-a304-737aecba251b"}}},{"cell_type":"markdown","source":["## 빅데이터와 SQL: 스파크 SQL\n- 스파크 2.0 버전에는 하이브를 지원할 수 있는 상위 호환 기능으로 <strong>ANSI-SQL과 HiveQL을 모두 지원</strong>하는 자체 개발 파서가 포함됨\n- 스파크 SQL은 <strong>DataFrame과의 뛰어난 호환성</strong> 덕분에 다양한 기업에서 강력한 기능으로 자리매김할 것임\n  - 2016년 말 페북은 스파크 워크로드를 가동하기 시작했고 효과를 봤다고 발표함\n    1. 4.5~6배의 CPU 성능 개선\n    2. 3~4배의 자원 예약 개선\n    3. 최대 5배의 지연 시간 감소\n\n- 스파크 SQL은 OLTP가 아닌 <strong>OLAP</strong> DB로 동작함\n  - [OLTP vs OLAP 참고](https://too612.tistory.com/511)\n  - OLTP(OnLine Transaction Processing)\n    - 실제 데이터를 수정하는 작업 중심(트랜잭션 중심 / row 단위에 초점)\n  - OLAP(OnLine Analytic Processing)\n    - 데이터를 사용자의 요구와 목적에 맞게 조회하는 작업 중심(정보 중심 / column 단위에 초점)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b041c280-458b-43ec-babc-161720b179a0"}}},{"cell_type":"markdown","source":["### 스파크와 하이브의 관계\n- 스파크 SQL은 하이브 메타스토어를 사용하므로 하이브와 잘 <strong>연동</strong>할 수 있음\n  - 하이브 메타스토어: 하이브에서 생성한 테이블 스키마를 저장하는 공간\n  - [메타스토어 참고](https://spidyweb.tistory.com/231)\n  \n- 스파크 SQL은 하이브 메타스토어에 접속하여 <strong>조회할 파일 수를 최소화하기 위해 메타데이터를 참조</strong>\n  - 이 기능은 기존 하둡 환경의 모든 워크로드를 <strong>스파크로 이관</strong>하려는 사용자들에게 인기"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e764fa63-218a-491b-885b-17037aef1131"}}},{"cell_type":"markdown","source":["## 스파크 SQL 쿼리 실행 방법"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5f073a4e-ee97-498b-b657-66bb4cc44bd2"}}},{"cell_type":"markdown","source":["### 스파크 SQL CLI\n- 스파크 SQL CLI(Command Line Interface)\n\n- 로컬 환경의 명령행에서 기본 스파크 SQL 쿼리를 실행할 수 있는 편리한 도구\n\n- 쓰리프트 JDBC서버와 통신 불가능\n  - 쓰리프트(thrift)?\n    - 서로 다른 언어간에 데이터 직렬화를 제공을 위한 인터페이스 정의 언어이자 이진 통신 프로토콜\n    - 스파크의 쓰리프트 서버는 여러 사용자의 JDBC 및 ODBC 접속을 받아 사용자의 쿼리를 스파크 SQL 세션으로 실행\n  - 참조\n    - [쓰리프트](https://ko.wikipedia.org/wiki/%EC%95%84%ED%8C%8C%EC%B9%98_%EC%8A%A4%EB%A6%AC%ED%94%84%ED%8A%B8)\n    - [쓰리프트](https://thebook.io/006908/part02/ch05/03/03/)\n    - [데이터 직렬화](https://hub1234.tistory.com/26)\n    \n- 사용하려면 스파크 디렉터리에서 다음 명령을 실행\n  - ./bin/spark-sql\n  - 스파크가 설치된 경로의 conf 디렉터리에서 hive-site.xml, core-site.xml, hdfs-site.xml 파일을 배치해서 하이브를 사용할 수 있는 환경 구성"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0508e1db-fbbf-436c-a538-ad5fe463f781"}}},{"cell_type":"markdown","source":["### 스파크의 프로그래밍 SQL 인터페이스\n- 스파크에서 지원하는 언어 API로 비정형 SQL 실행 가능\n- SparkSession 객체의 sql 메서드 사용 -> DataFrame 반환\n  - 다른 트랜스포메이션과 마찬가지로 즉시 실행 X 지연 처리\n- SQL과 DataFrame은 완벽하게 연동 가능\n  - DataFrame 생성 -> SQL 처리 -> DataFrame 반환"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"04dafa84-e3e3-4376-b8d9-72c9b90f91db"}}},{"cell_type":"code","source":["spark.sql(\"SELECT 1+1\").show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e9966212-7754-4acb-b689-055467bae78e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-------+\n|(1 + 1)|\n+-------+\n|      2|\n+-------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+\n(1 + 1)|\n+-------+\n      2|\n+-------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["path= \"/FileStore/tables/2010_summary.json\"\nspark.read.json(path).createOrReplaceTempView('some_sql_view')#DataFrame을 SQL에서 사용할 수 있도록 뷰 등록"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"54a58409-f721-4d4d-a980-e33bbd0b5228"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["spark.sql(\"select dest_country_name,sum(count) from some_sql_view group by dest_country_name\")\\\n.where(\"dest_country_name like 'S%'\").where(\"'sum(count)' > 10\") #SQL 결과를 DataFrame으로 반환"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"26937f4c-a444-46b9-b123-ad41cc728a73"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[13]: DataFrame[dest_country_name: string, sum(count): bigint]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[13]: DataFrame[dest_country_name: string, sum(count): bigint]</div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Chapter10","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":4413081568098459}},"nbformat":4,"nbformat_minor":0}
